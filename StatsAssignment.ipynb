{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "# MSc in Bioinformatics and Theoretical Systems Biology - Maths and Stats Assignment 2020/21\n",
    "\n",
    "This assignment is to be completed in Python, R or Julia and returned as a clean Jupyter notebook cleared of its output. This is important otherwise Turnitin will reject the submission.\n",
    "\n",
    "There are 4 types of cells used in this notebook:\n",
    "1. Cells containing tasks and instructions to be completed. Do not edit these. These are clearly labelled.\n",
    "2. Cells in which you are meant to provide an answer in Markdown format.\n",
    "3. Cells containing code that defines e.g. which packages to load, but can also contain routines and snippets of codes that you should use.\n",
    "4. Cells that contain the Python/R/Julia code that you write to solve the problems set.\n",
    "\n",
    "Each of these cells will contain explit comments at the top telling you whether to edit or not edit a cell. In Code cells comments are specified by the \"#\" character. In the Markdown Answer Cells, replace the xxx by your answer, whenever these are present. You will have to execute all code and Markdown cells in order to (i) make use of the provided code, and (ii) format the markdown appropriately.\n",
    "\n",
    "There are four problems to be tackled:\n",
    "1. Data exploration [40%]\n",
    "2. Hypothesis testing [20%]\n",
    "3. Regression [20%]\n",
    "4. Classification [20%]\n",
    "\n",
    "For each questions there several parts of different difficulty. Where appropriate, further reading will be given at the start of each question.\n",
    "\n",
    "You will have to specify which language (and version) you used and all packages needed in order to run all Code cells. Please add this information in the next two cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Provide your answer here]**\n",
    "- The kernel for this Jupyter notebook is R, version 3.6.1, with the following packages: ggplot2, fitdistrplus, dplyr, e1071, caret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library('ggplot2')\n",
    "library('fitdistrplus')\n",
    "library('dplyr')\n",
    "library('e1071')\n",
    "library('caret')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "## Problem 1: data exploration\n",
    "\n",
    "We consider a subset of data coming from a putative association study where researchers collected various metrics and phenotypes to find associations with a putative generic cardiovascular disease.\n",
    "All recruited subjects are adults.\n",
    "\n",
    "For each subject several __predictor variables__ are recorded: sex (1 for female, 0 for male), height (in cm), mass (in kg), whether he/she is a smoker (1) or not (0), whether he/she is a drinker (1) or not (0), and levels of 5 different metabolites (labelled A-E).\n",
    "**Each subject has a unique ID number**. \n",
    "\n",
    "For each subject a disease score, which is the __response__ variable, measuring the severity of the disease phenotype in arbitrary units, is provided.\n",
    "The data is provided in the file `association_data.csv`.\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Load the dataset `association_data.csv`.\n",
    "How many unique records of subjects do we have? How many unique predictor variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setwd(\"~/Imperial/Maths/Stats/Assignment\")\n",
    "asso = read.csv('association_data.csv')\n",
    "\n",
    "summary(asso)\n",
    "\n",
    "for (attribute in names(asso)){\n",
    "  ua = length(unique(asso[,attribute]))\n",
    "  cat(ua, \"unique\", attribute, \"instances\", \"\\n\")\n",
    "}\n",
    "\n",
    "#note: height is given in cm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Provide your answer here]**\n",
    "- The number of unique records of subjects in the dataset is: 1000\n",
    "- The number of variables in the dataset is: 12 (but 11 predictor variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "### Part 2\n",
    "\n",
    "Produce a plot to illustrate the distribution of variables `smoker`, `mass`, `metabolite_A`. Choose the most appropriate visualisation depending on the type of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_frame = data.frame(Smoke = c(sum(asso$smoker),(length(asso$smoker) - sum(asso$smoker))),\n",
    "                         Labels = c(\"Smoker\", \"Non-smoker\"))\n",
    "smoke_frame$perc = smoke_frame$Smoke / length(asso$smoke) * 100\n",
    "\n",
    "\n",
    "ggplot(smoke_frame, aes(x=\"\", y=Smoke, fill = Labels)) +\n",
    "  geom_bar(stat=\"identity\", width=1, color=\"white\") +\n",
    "  coord_polar(\"y\", start=0) + \n",
    "  theme_void() +\n",
    "  geom_text(aes(y = c(100, 700), label = perc)) +\n",
    "  labs(title = \"Smoker Distribution\", y = \"Smoker\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The following two functions are taken from a data modelling assignment\n",
    "#I took in my undergrad. They allow me to easily plot histograms as well as calculate distribution skew.\n",
    "\n",
    "calc_skew = function(my_dat, my_mean, my_median, my_sdev, type){ #returns skewness of dist\n",
    "  skew = (3*(my_mean - my_median))/my_sdev\n",
    "}\n",
    "\n",
    "create_hist = function(dframe,atrib,Titl,width,se){\n",
    "  my_dat = dframe[,atrib]\n",
    "  my_dat = my_dat[!is.na(my_dat)] # remove missing vals\n",
    "  my_min = min(my_dat)\n",
    "  my_min = signif(my_min,3)\n",
    "  my_max = max(my_dat)\n",
    "  my_max = signif(my_max,3)\n",
    "  \n",
    "  my_mean = mean(my_dat) #calculate summary stats for skew and additional plot elements\n",
    "  my_median = median(my_dat)\n",
    "  my_sdev = sd(my_dat)\n",
    "  \n",
    "  my_skew = calc_skew(my_dat, my_mean, my_median, my_sdev, 2)\n",
    "  print(my_skew)\n",
    "  \n",
    "  my_dat = as.data.frame(my_dat)\n",
    "  \n",
    "  ggplot(my_dat, aes(x=my_dat, color = \"Lines\")) + \n",
    "    scale_x_continuous(breaks = seq(floor(my_min), ceiling(my_max),by=se),atrib)+\n",
    "    geom_histogram(binwidth = width, col = \"Blue\") +\n",
    "    geom_vline(aes(xintercept=my_mean, col=\"Mean\")) +\n",
    "    geom_vline(aes(xintercept=my_median, col=\"Median\"))+\n",
    "    labs(title = Titl, y = \"Frequency\")\n",
    "  \n",
    "}\n",
    "\n",
    "create_hist(asso,'mass', \"Mass Distribution\", 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_hist(asso,'metabolite_A', \"Metabolite A Distribution\", 0.01,0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "### Part 3\n",
    "\n",
    "Write a function that returns the Body Mass Index (BMI). Learn from a literature search how to calculate BMI.\n",
    "Calculate BMI for each subject and add it as new __predictor variable__ in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asso$bmi = asso$mass / (asso$height/100)^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "### Part 4\n",
    "\n",
    "Calculate the correlation matrix between __quantitative__ (numerical) predictors. Use this information to impute any missing values, if possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Produce the correlation matrix ###\n",
    "cor(asso[,2:length(asso)], use= 'pairwise.complete.obs')\n",
    "\n",
    "### Gen Summary Statistics to see number of NA's ##\n",
    "\n",
    "summary(asso) # see clearly that there's 2 NA's in metabolite_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = lm(metabolite_A~metabolite_B, data = asso)[\"coefficients\"] # Regression model gives us our y = mx + c line between met a and b\n",
    "\n",
    "reg_grad= reg$coefficients[1]\n",
    "reg_int = reg$coefficients[2]\n",
    "\n",
    "new_A = asso[is.na(asso[\"metabolite_A\"]),\"metabolite_B\"] * reg_grad + reg_int\n",
    "\n",
    "for (A in new_A){\n",
    "  asso[is.na(asso[\"metabolite_A\"]),\"metabolite_A\"] <- A\n",
    "}\n",
    "\n",
    "summary(asso) # shows missing values have been removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "### Part 5\n",
    "\n",
    "Assuming that a disease status is recorded when the disease score is greater than 1, add a new __response variable__ in the dataset defining the diseased `status` of each subject, either non diseased (0) or diseased (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asso$status = ifelse((asso[,\"disease_score\"] > 1),1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "## Problem 2: hypothesis testing\n",
    "\n",
    "Starting from the same dataset in Problem 1, provide answers for the following questions.\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Given this sample space of subjects, what is the probability that a given subject is diagnosed as diseased? What is the probability that a subject is diagnosed as diseased given that he/she is not a smoker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the probability of diseased given sample set\n",
    "\n",
    "prob_diseased = sum(asso$status)/nrow(asso)\n",
    "\n",
    "\n",
    "#probability of diseased given the fact they smoke\n",
    "smokers = asso[asso$smoker == 1,]\n",
    "\n",
    "prob_dis_smoker = sum(smokers$status)/nrow(smokers)\n",
    "\n",
    "prob_diseased\n",
    "prob_dis_smoker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Provide your answer here]**\n",
    "- The probability that a subject is diseased is: 0.383\n",
    "- The probability that a subject is diseased given that she/he is not a smoker is: 0.502 (to 3sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "### Part 2\n",
    "\n",
    "Assuming that they distributed as a Normal distribution $N(\\mu, \\sigma^2)$, provide an estimate of $\\mu$ and $\\sigma^2$ for the distributions of height and mass separately for males and females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_param_estimates = function(dat, dist){\n",
    "  mea = mean(dat)\n",
    "  sdev = sd(dat)\n",
    "  fd = fitdist(dat, dist, method = \"mle\")\n",
    "  fit_mea = fd$estimate[1]\n",
    "  fit_sd = fd$estimate[2]\n",
    "  \n",
    "  param_estimates = data.frame(\"Frequentist estimate\" = c(mea,sdev),\n",
    "                               \"Maximum Likelihood Estimate\" = c(fit_mea,fit_sd))\n",
    "  rownames(param_estimates) = c(\"Mean\", \"Standard Deviation\") \n",
    "  \n",
    "  return(param_estimates)\n",
    "}\n",
    "\n",
    "males = asso[asso$sex == 0,]\n",
    "females = asso[asso$sex == 1,]\n",
    "\n",
    "#Estimate params:\n",
    "print(\"Male Height Parameter Estimates\")\n",
    "get_param_estimates(males$height, \"norm\")\n",
    "print(\"Female Height Parameter Estimates\")\n",
    "get_param_estimates(females$height, \"norm\")\n",
    "\n",
    "print(\"Male Mass Parameter Estimates\")\n",
    "get_param_estimates(males$mass, \"norm\")\n",
    "print(\"Female Mass Parameter Estimates\")\n",
    "get_param_estimates(females$mass, \"norm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "### Part 3\n",
    "\n",
    "Test whether height is different between males and females. Perform the same test on the mass variable. Define (in words) which ones are your null and alternative hypotheses and significance threshold. Finally, discuss (in words) any conclusion you can make out the results of your statistical tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_t = t.test(males$height, females$height)\n",
    "mass_t = t.test(males$mass, females$mass)\n",
    "\n",
    "height_t\n",
    "mass_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Provide your answer here]**\n",
    "\n",
    "- T Test Height: <br>\n",
    "Null Hypothesis --> no difference in mean of female height and mean of male height <br>\n",
    "Alternative Hypothesis --> difference in mean of female height and mean of male height not equal to zero <br>\n",
    "Significance Threshold --> 0.05<br>\n",
    "Conclusion --> since p is > 0.05 we must accept the null hypothesis (i.e. there is no difference in female and male height means)<br>\n",
    "<br>\n",
    "- T Test Mass: <br>\n",
    "Null Hypothesis --> no difference in mean of female mass and mean of male mass <br>\n",
    "Alternative Hypothesis --> difference in mean of female mass and mean of male mass not equal to zero <br>\n",
    "Significance Threshold --> 0.05 <br>\n",
    "Conclusion --> since p < 0.05, we can reject the null hypothesis (i.e. there is a significant difference between female and male weight means) <br>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "### Part 4\n",
    "\n",
    "Repeat the statistical test in Part 3 for all numerical predictor variables in the dataset. How many tests are significant with $\\alpha=0.05$?\n",
    "Calculate corrected p-values for multiple tests using a Bonferroni correction. \n",
    "Learn what the Bonferroni correction implies from a literature search. \n",
    "How many tests are significant after correcting for multiple tests? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "test_frame = c()\n",
    "\n",
    "for(atrib in names(asso)[3:length(names(asso))]){ #skip sex and id\n",
    "  itt_test = t.test(males[,atrib], females[,atrib])\n",
    "  itt_p = itt_test$p.value\n",
    "  itt_row = data.frame(p = itt_p)\n",
    "  test_frame = rbind(test_frame, itt_row)\n",
    "}\n",
    "\n",
    "test_frame$significance = ifelse((test_frame[,\"p\"] <= alpha),T,F)\n",
    "row.names(test_frame) = names(asso)[3:length(names(asso))]\n",
    "print(\"Significant Results: \")\n",
    "test_frame[test_frame$significance == T,] #shows mass and bmi have significant differences in mean\n",
    "\n",
    "### Bonferoni Correction ###\n",
    "\n",
    "test_frame$bonferoni = ifelse((test_frame[,\"p\"] <= alpha/ncol(test_frame)),T,F)\n",
    "print(\"Significant Results (bonferoni correction): \")\n",
    "test_frame[test_frame$bonferoni == T,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "## Problem 3: regression\n",
    "\n",
    "Assume you have been provided with a new __predictor variable__ indicating a generic glucose index level. We know that such glucose index is related to the variable `metabolite_D` given in the previous dataset.\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Load the new dataset called `glucose_data.csv` which gives the measure of a generic glucose level (`glucose_index`) for each tested subject. Perform a regression where `metabolite_D` is the predictor and `glucose_index` is the response variable. Be aware to merge the two data sets by matching subject IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"~/Imperial/Maths/Stats/Assignment\")\n",
    "asso = read.csv(\"asso.csv\")\n",
    "gluc = read.csv(\"glucose_data.csv\")\n",
    "\n",
    "asso = left_join(asso, gluc, by=\"subject\")\n",
    "\n",
    "\n",
    "lin_mod = lm(glucose_index~metabolite_D,data = asso)\n",
    "#summary(lin_mod)\n",
    "\n",
    "int = lin_mod$coefficients[1]\n",
    "grad = lin_mod$coefficients[2]\n",
    "print(\"Formula: \")\n",
    "cat(\"glucose = metabolite_D * \",grad, \" + \",int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "## Problem 4: classification\n",
    "\n",
    "### Part 1\n",
    "\n",
    "Implement an algorithm to predict the disease status of a subject given all response variables provided in the dataset. You are free to choose the appropriate statistical tool you prefer. Assess the performance of your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(42)\n",
    "\n",
    "\n",
    "partition = function(dset){ #return list of train and test sets\n",
    "  train_ind = createDataPartition(y= dset$status, p = 0.75, list = FALSE)\n",
    "  train = dset[train_ind,]\n",
    "  test = dset[-train_ind,]\n",
    "  ret = list(train, test)\n",
    "  return(ret)\n",
    "} \n",
    "\n",
    "\n",
    "\n",
    "## Base dataset - no reduction\n",
    "base = asso #Store a base dataset with no dim reduction\n",
    "base[,c(\"subject\",\"disease_score\")] = NULL #remove the subject and disease score vars\n",
    "\n",
    "\n",
    "\n",
    "## dr set - delete by weak correlation to response var\n",
    "stat_cors = cor(asso[,2:length(asso)], use ='pairwise.complete.obs')[,\"status\"] \n",
    "threshold = 0.2\n",
    "to_del = names(stat_cors[abs(stat_cors) < threshold]) #get list of vars to remove from df \n",
    "\n",
    "dr = asso\n",
    "for(name in to_del){\n",
    "  dr[,name] = NULL\n",
    "}\n",
    "dr[,c(\"disease_score\",\"subject\")] = NULL\n",
    "\n",
    "## PC set - combine into PC's covering > ... variance of dataset\n",
    "pc = asso\n",
    "status = asso$status\n",
    "pc[,c(\"subject\",\"status\",\"disease_score\")] = NULL\n",
    "pc = as.data.frame(scale(pc))\n",
    "pc = prcomp(pc,scale=T)\n",
    "#pc\n",
    "pc = as.data.frame(pc$x[,1:7]) #contains > 95% of variance of set, uncomment to see this\n",
    "pc = cbind(pc, status)\n",
    "###\n",
    "\n",
    "gen_svm = function(dat){\n",
    "  \n",
    "  #partition and format\n",
    "  p_dat = partition(dat)\n",
    "  \n",
    "  train_dat = as.data.frame(p_dat[1])\n",
    "  train_dat$status = as.factor(train_dat$status)\n",
    "  test_dat = as.data.frame(p_dat[2])\n",
    "  test_dat$status = as.factor(test_dat$status)\n",
    "  \n",
    "  svm_dat = svm(status ~ ., data = train_dat, kernel = \"radial\", cost =5, scale = F)\n",
    "  svm_pred = predict(svm_dat, test_dat)\n",
    "  \n",
    "  ret = data.frame(status = test_dat$status, pred = svm_pred)\n",
    "  cmat = confusionMatrix(data = ret$pred, reference = ret$status)\n",
    "  print(cmat)\n",
    "  return(svm_dat)\n",
    "  \n",
    "}\n",
    "print(\"Base Dataset SVM Results: \")\n",
    "base_SVM = gen_svm(base)\n",
    "print(\"Dimensionality Reduced Dataset SVM Results: \")\n",
    "dr_SVM = gen_svm(dr)\n",
    "print(\"Principal Component Reduced Dataset SVM Results: \")\n",
    "pc_SVM = gen_svm(pc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Do not edit the contents of this cell]**\n",
    "\n",
    "### Part 2\n",
    "\n",
    "Given the classifier you devised in Part 1, predict the disease status of the following subject:\n",
    "- subject: ID1986\n",
    "- sex: 1\n",
    "- height: 180.2\n",
    "- mass: 70.1\n",
    "- smoker: 1\n",
    "- drinker: 0\n",
    "- metabolite_A: 0.5\n",
    "- metabolite_B: 1.2\n",
    "- metabolite_C: 0.5\n",
    "- metabolite_D: 8.5\n",
    "- metabolite_E: 10.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_subject = data.frame(subject = \"ID1986\",\n",
    "                        sex = 1,\n",
    "                        height = 180.2,\n",
    "                        mass=70.1,\n",
    "                        smoker=1,\n",
    "                        drinker= 0,\n",
    "                        metabolite_A = 0.5,\n",
    "                        metabolite_B= 1.2,\n",
    "                        metabolite_C= 0.5,\n",
    "                        metabolite_D= 8.5,\n",
    "                        metabolite_E= 10.2)\n",
    "\n",
    "new_subject$bmi = new_subject$mass / (new_subject$height/100)^2\n",
    "\n",
    "predict(dr_SVM, new_subject) #subject is diseased!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Provide your answer here]**\n",
    "\n",
    "<h2>Preprocessing </h2><br>\n",
    "For this exercise several datasets were generated in an attempt to attain the best performing classifier. The first of these was the base dataset - a set that contains all variables appart from the subject ID and the disease score (since status is directly calculated from the disease score, It seemed redundant to retain it in our dataset - the model would be classifying based on high/low disease score rather than the underlying relationship between the predictor variables). <br> \n",
    "<br>\n",
    "The second dataset was a dimensionality reduced set. This dataset removed variables that weakly correlated with the class variable (the idea being that these variables were uninformative so removing them helped to aleviate the curse of dimensionality allowing for more accurate classification). <br>\n",
    "<br>\n",
    "The Third dataset contained the first 7 principal components of the dataset. This accounted for ~95% of the variation in the data, meaning I could aleviate the curse of dimensionality while retaining the majority of the variance.This was used to help to confirm the validity of the dimensionality reduced set<br>\n",
    "<br>\n",
    "<h2> Classifier</h2><br>\n",
    "For this exercise, all classification was performed using Support Vector Machines <br>\n",
    "<br>\n",
    "\n",
    "<h2> Evaluating Classification: </h2><br>\n",
    "    \n",
    "The classifier produced by the Base dataset performed well with an accuracy of \\~81%. When analysing the confusion matrix it is apparent that there is a bias towards false negative predictions (since there are 30 false negative predictions but only 18 false positive predictions). <br>\n",
    "<br>\n",
    "The classifier produced by the Dimensionality reduced dataset on the other hand vastly outperformed the one created by the Base dataset with an accuracy of \\~93%. Unlike the Base set classifier, it does not seem to show a similar bias with and equal number of false positives and false negatives. <br>\n",
    "<br>\n",
    "The classifier produced by the PCA dataset shows a very similar accuracy to the Dimensionality Reduced classifier (~92%) which implies that, despite only retaining 3 variables, it is able to produce models that encompas ~95% of the total variation of the dataset thus validating the decision to excise the other variables from the set. <br>  \n",
    "<br>\n",
    "<h2>Categorising the new subject:</h2> <br>\n",
    "<br>\n",
    "Using the best performing classifier from pt1 (the dimensionality reduced Support Vector Machine), I was able to classify the new instance as diseased"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
